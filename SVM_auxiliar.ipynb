{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto ML\n",
    "\n",
    "Trabalho de:\n",
    "\n",
    "* Bárbara Simões Neto up\n",
    "* Beatriz Castro up\n",
    "* Rodrigo Couto up202104696\n",
    "\n",
    "\n",
    "sites usados até então:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html\n",
    "\n",
    "https://link.springer.com/article/10.1007/s10618-021-00737-9 (so vi as imagens para perceber o que era os diferentes tipos de datasets que o chatzaome deu, elas sao bastantes intuitivas)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles, make_blobs\n",
    "\n",
    "\n",
    "#Gerar datasets\n",
    "\n",
    "def generate_mixed_dataset(n_samples, n_features, n_categorical, n_ordinal, n_integer, \n",
    "                           n_classes, class_balance=None, noise=0.0, \n",
    "                           dataset_type='linear', random_state=42):\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    if dataset_type == 'linear':\n",
    "        X, y = make_classification(n_samples=n_samples, n_features=n_features, \n",
    "                                  n_informative=n_features, n_redundant=0, \n",
    "                                  n_classes=n_classes, weights=class_balance, \n",
    "                                  flip_y=noise, random_state=random_state, class_sep=2)\n",
    "    elif dataset_type == 'moons':\n",
    "        X, y = make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
    "        if n_features > 2:\n",
    "            extra_features = np.random.rand(n_samples, n_features - 2) * 100\n",
    "            X = np.hstack([X, extra_features])\n",
    "    elif dataset_type == 'circles':\n",
    "        X, y = make_circles(n_samples=n_samples, noise=noise, random_state=random_state)\n",
    "        if n_features > 2:\n",
    "            extra_features = np.random.rand(n_samples, n_features - 2) * 100\n",
    "            X = np.hstack([X, extra_features])\n",
    "    elif dataset_type == 'blobs':\n",
    "        X, y = make_blobs(n_samples=n_samples, centers=n_classes, cluster_std=noise*10, \n",
    "                          random_state=random_state)\n",
    "        if n_features > 2:\n",
    "            extra_features = np.random.rand(n_samples, n_features - 2) * 100\n",
    "            X = np.hstack([X, extra_features])\n",
    "    else:\n",
    "        raise ValueError(\"Tipo de dataset não suportado. Use 'linear', 'moons', 'circles' ou 'blobs'.\")\n",
    "\n",
    "    categorical_data = np.random.choice(['A', 'B', 'C', 'D'], size=(n_samples, n_categorical))\n",
    "\n",
    "    ordinal_data = np.random.randint(1, 6, size=(n_samples, n_ordinal))  #podem mudar estes valores para criar dataset mais especificos\n",
    "\n",
    "    integer_data = np.random.randint(0, 100, size=(n_samples, n_integer))  #podem mudar estes valores para criar dataset mais especificos\n",
    "\n",
    "    # Combina todos os dados em um único array\n",
    "    data = np.hstack([X, categorical_data, ordinal_data, integer_data])\n",
    "\n",
    "    columns = [f'Continuous_{i+1}' for i in range(n_features)] + \\\n",
    "              [f'Categorical_{i+1}' for i in range(n_categorical)] + \\\n",
    "              [f'Ordinal_{i+1}' for i in range(n_ordinal)] + \\\n",
    "              [f'Integer_{i+1}' for i in range(n_integer)]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # Adiciona a coluna target\n",
    "    df['Target'] = y\n",
    "\n",
    "    # Converte as colunas para os tipos corretos\n",
    "    for col in df.columns:\n",
    "        if col.startswith('Continuous'):\n",
    "            df[col] = df[col].astype(float)\n",
    "        elif col.startswith('Ordinal') or col.startswith('Integer'):\n",
    "            df[col] = df[col].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de dataset a criar\n",
    "df_linear = generate_mixed_dataset(n_samples=300, n_features=15, n_categorical=4, n_ordinal=3, n_integer=3,\n",
    "                                   n_classes=3, class_balance=[0.6, 0.3, 0.1], noise=0.2, dataset_type='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 - Linear:\n",
      "   Continuous_1  Continuous_2  Continuous_3  Continuous_4  Continuous_5  \\\n",
      "0      6.989648     -1.945206      3.023859      1.182231      0.278835   \n",
      "1      3.006515     -4.898161      6.333545     -0.275117     -0.568798   \n",
      "2     -2.969395     -2.618095      2.442972      1.146152     -1.361517   \n",
      "3      4.504825     -0.694414     -1.174836     -0.794338      3.717030   \n",
      "4     -3.487806      1.616072      1.264624      4.659925     -0.047828   \n",
      "\n",
      "   Continuous_6  Continuous_7  Continuous_8  Continuous_9  Continuous_10  ...  \\\n",
      "0      5.244402     -0.559871      2.010185     -2.379406       1.560066  ...   \n",
      "1      3.374050      1.749962     -1.692300      0.005870       4.145944  ...   \n",
      "2      0.898219     -2.436304     -1.847875      3.278797       4.552161  ...   \n",
      "3     -0.748132     -2.793930      2.759622     -1.252518      -2.317956  ...   \n",
      "4      5.085898      0.254505      0.702009     -1.098722      -1.904772  ...   \n",
      "\n",
      "   Categorical_2  Categorical_3  Categorical_4  Ordinal_1  Ordinal_2  \\\n",
      "0              D              A              C          5          2   \n",
      "1              D              A              A          2          5   \n",
      "2              B              C              C          1          5   \n",
      "3              C              D              A          4          2   \n",
      "4              D              D              C          1          2   \n",
      "\n",
      "  Ordinal_3 Integer_1 Integer_2 Integer_3  Target  \n",
      "0         4        11        86        11       1  \n",
      "1         5        12        24        44       1  \n",
      "2         1        18        54        99       0  \n",
      "3         2        44         7        92       1  \n",
      "4         5        52        54        31       2  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Dataset 1\n",
    "print(\"Dataset 1 - Linear:\")\n",
    "print(df_linear.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texto do melhor dataset para o svm linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Dataset for Linear SVM:\n",
      "   Continuous_1  Continuous_2  Continuous_3  Continuous_4  Continuous_5  \\\n",
      "0      0.527723     -3.232887      1.941391      1.036016      1.621397   \n",
      "1      3.448069      3.495373     -3.907942      1.456847      2.347071   \n",
      "2     -1.333755     -0.067673     -3.923265     -1.533233      4.221876   \n",
      "3      3.191603     -0.293859      1.750052     -0.946933      1.627680   \n",
      "4      1.049949      4.971198      0.938902     -3.968051      1.816586   \n",
      "\n",
      "   Continuous_6  Continuous_7  Continuous_8  Continuous_9  Continuous_10  ...  \\\n",
      "0      5.309474     -1.109027      6.783783      3.807855       0.176956  ...   \n",
      "1      0.515985      1.159086      1.079827     -0.586888      -1.714697  ...   \n",
      "2      1.959587     -4.905835     -2.831533     -3.513112      -6.041880  ...   \n",
      "3     -1.153647      0.225652     -3.055964     -5.367286       1.982387  ...   \n",
      "4     -3.008779      2.637539     -4.835088     -3.356418      -4.147073  ...   \n",
      "\n",
      "   Continuous_20  Integer_1  Integer_2  Integer_3  Integer_4  Integer_5  \\\n",
      "0      -5.894015         51         92         14         71         60   \n",
      "1       6.027891         74         74         87         99         23   \n",
      "2      -4.373229          1         87         29         37          1   \n",
      "3       3.550316         32         75         57         21         88   \n",
      "4       6.044122         41         91         59         79         14   \n",
      "\n",
      "   Integer_6  Integer_7  Integer_8  Target  \n",
      "0         20         82         86       0  \n",
      "1          2         21         52       0  \n",
      "2         63         59         20       1  \n",
      "3         48         90         58       0  \n",
      "4         61         61         46       0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "#gerar dataset adequado\n",
    "\n",
    "df_svm_linear = generate_mixed_dataset(n_samples=500, n_features=20, n_categorical=0, n_ordinal=0, n_integer=8,\n",
    "                                                  n_classes=2, class_balance=None, noise=0, dataset_type='linear')\n",
    "\n",
    "print(\"Best Dataset for Linear SVM:\")\n",
    "print(df_svm_linear.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy (Second Dataset - CV=5): 0.88 (± 0.03)\n",
      "\n",
      "Fold Accuracies:\n",
      "Fold 1: 0.90\n",
      "Fold 2: 0.83\n",
      "Fold 3: 0.93\n",
      "Fold 4: 0.87\n",
      "Fold 5: 0.87\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df_svm_linear.drop('Target', axis=1)  \n",
    "y = df_svm_linear['Target']  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# standerizar as features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Training model\n",
    "model = LinearSVC(C=0.1,random_state=42)  \n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Predicts\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#novo dataset para avaliar o modelo\n",
    "df_svm_linear_2 = generate_mixed_dataset(n_samples=150, n_features=20, n_categorical=0, n_ordinal=0, n_integer=8,\n",
    "                                           n_classes=2, class_balance=None, noise=0, dataset_type='linear')\n",
    "\n",
    "\n",
    "\n",
    "X_2 = df_svm_linear_2.drop('Target', axis=1)\n",
    "y_2 = df_svm_linear_2['Target']\n",
    "\n",
    "\n",
    "X_2 = scaler.transform(X_2)\n",
    "\n",
    "y_pred_2 = model.predict(X_2)\n",
    "\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# cross-validation \n",
    "cv_scores_2 = cross_val_score(model, X_2, y_2, cv=5, scoring='accuracy')\n",
    "\n",
    "# Resultados\n",
    "print(f\"Cross-Validation Accuracy (Second Dataset - CV=5): {cv_scores_2.mean():.2f} (± {cv_scores_2.std():.2f})\")\n",
    "print(\"\\nFold Accuracies:\")\n",
    "for i, score in enumerate(cv_scores_2, start=1):\n",
    "    print(f\"Fold {i}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texto do melhor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo do modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
